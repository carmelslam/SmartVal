<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>× ×™×§×•×œ â€“ ×¢×•×–×¨×ª ×“×™×’×™×˜×œ×™×ª</title>
  <script type="module" src="./webhook.js"></script>
  <script type="module" src="./helper.js"></script>

  <link rel="icon" type="image/webp" href="https://carmelcayouf.com/wp-content/uploads/2025/06/g.webp">
  <link rel="shortcut icon" href="https://carmelcayouf.com/wp-content/uploads/2025/04/logo-yaron.webp">
  <link rel="apple-touch-icon" href="https://carmelcayouf.com/wp-content/uploads/2025/04/logo-yaron.webp">
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      margin: 0;
      padding: 20px;
      display: flex;
      justify-content: center;
      align-items: center;
      min-height: 100vh;
      box-sizing: border-box;
    }
    .container {
      max-width: 480px;
      background: #fff;
      padding: 35px;
      border-radius: 18px;
      box-shadow: 0 8px 32px rgba(0,0,0,0.12);
      text-align: center;
      position: relative;
      width: 90%;
      backdrop-filter: blur(10px);
      border: 1px solid rgba(255,255,255,0.2);
    }
    .logo img {
      width: 120px;
      margin-bottom: 15px;
    }
    .title { 
      font-size: 26px; 
      font-weight: 700; 
      margin-bottom: 8px; 
      color: #2d3748;
      letter-spacing: -0.5px;
    }
    .subtitle { 
      font-size: 16px; 
      color: #718096; 
      margin-bottom: 8px; 
      font-weight: 500;
    }
    h2 {
      font-size: 22px;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      margin-bottom: 25px;
      font-weight: 600;
      letter-spacing: -0.3px;
    }
    input {
      width: 100%;
      padding: 14px 16px;
      font-size: 15px;
      margin-bottom: 18px;
      border-radius: 14px;
      border: 1.5px solid #e2e8f0;
      box-sizing: border-box;
      transition: all 0.3s ease;
      background: #f7fafc;
      color: #2d3748;
      font-weight: 500;
    }
    
    input:focus {
      outline: none;
      border-color: #667eea;
      background: #fff;
      box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
      transform: translateY(-1px);
    }

    /* Modern input container with integrated microphone */
    .input-container {
      position: relative;
      margin-bottom: 20px;
    }
    
    .input-with-mic {
      width: 100%;
      padding: 16px 50px 16px 18px;
      font-size: 15px;
      border-radius: 18px;
      border: 1.5px solid #e2e8f0;
      box-sizing: border-box;
      transition: all 0.3s ease;
      background: #f7fafc;
      resize: none;
      min-height: 90px;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      color: #2d3748;
      font-weight: 500;
      line-height: 1.5;
    }
    
    .input-with-mic:focus {
      outline: none;
      border-color: #667eea;
      background: #fff;
      box-shadow: 0 0 0 4px rgba(102, 126, 234, 0.08);
      transform: translateY(-2px);
    }
    
    .mic-button {
      position: absolute;
      left: 12px;
      top: 50%;
      transform: translateY(-50%);
      width: 34px;
      height: 34px;
      border-radius: 50%;
      border: none;
      background: linear-gradient(135deg, #1e3a8a 0%, #3b82f6 100%);
      color: white;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 15px;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      box-shadow: 0 4px 12px rgba(30, 58, 138, 0.3);
    }
    
    .mic-button:hover {
      transform: translateY(-50%) scale(1.1);
      box-shadow: 0 4px 12px rgba(30, 58, 138, 0.4);
    }
    
    .mic-button:active {
      transform: translateY(-50%) scale(0.95);
    }
    
    .mic-button.recording {
      background: linear-gradient(135deg, #ff6b6b 0%, #ee5a52 100%);
      animation: pulse 1.5s ease-in-out infinite;
    }
    
    @keyframes pulse {
      0% { box-shadow: 0 2px 8px rgba(255, 107, 107, 0.3); }
      50% { box-shadow: 0 4px 16px rgba(255, 107, 107, 0.6); }
      100% { box-shadow: 0 2px 8px rgba(255, 107, 107, 0.3); }
    }
    
    /* Modern button container */
    .button-container {
      display: flex;
      gap: 12px;
      margin-top: 28px;
      justify-content: center;
    }
    
    .btn-modern {
      padding: 12px 24px;
      font-size: 15px;
      font-weight: 600;
      border: none;
      border-radius: 16px;
      cursor: pointer;
      transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 8px;
      min-width: 130px;
      letter-spacing: -0.2px;
    }
    
    .btn-send {
      background: linear-gradient(135deg, #16a34a 0%, #22c55e 100%);
      color: white;
      box-shadow: 0 6px 20px rgba(34, 197, 94, 0.3);
    }
    
    .btn-send:hover {
      transform: translateY(-3px);
      box-shadow: 0 10px 30px rgba(34, 197, 94, 0.4);
    }
    
    .btn-send:active {
      transform: translateY(-1px);
    }
    
    .btn-clear {
      background: rgba(255, 255, 255, 0.9);
      color: #4a5568;
      border: 1.5px solid #e2e8f0;
      backdrop-filter: blur(10px);
    }
    
    .btn-clear:hover {
      background: rgba(255, 255, 255, 1);
      border-color: #cbd5e0;
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }
    
    .btn-secondary {
      background: #64748b;
      color: white;
      border: 1.5px solid #64748b;
    }
    
    .btn-secondary:hover {
      background: #475569;
      border-color: #475569;
      transform: translateY(-2px);
      box-shadow: 0 4px 12px rgba(71, 85, 105, 0.3);
    }
    .floating-response {
      position: fixed;
      bottom: 30px;
      right: 30px;
      max-width: 380px;
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(20px);
      border: 1px solid rgba(102, 126, 234, 0.2);
      padding: 20px;
      border-radius: 18px;
      box-shadow: 0 12px 40px rgba(102, 126, 234, 0.15);
      font-size: 15px;
      color: #2d3748;
      z-index: 1000;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      line-height: 1.6;
      animation: slideInUp 0.3s ease-out;
    }

    @keyframes slideInUp {
      from {
        opacity: 0;
        transform: translateY(20px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    @media (max-width: 480px) {
      .floating-response {
        right: 20px;
        left: 20px;
        max-width: none;
        bottom: 20px;
      }
    }
  </style>
</head>
<body>
<div class="container">
  <div class="logo">
    <img src="https://carmelcayouf.com/wp-content/uploads/2025/06/g.webp" alt="Logo">
  </div>
  <div class="title">×™×¨×•×Ÿ ×›×™×•×£ ×©×××•×ª - ×¤×•×¨×˜×œ</div>
  <div class="subtitle">×©×××™ ×¨×›×‘ ×•×”×¢×¨×›×ª × ×–×§×™ ×¨×›×•×©</div>
  <h2>ğŸ‘©â€ğŸ’¼ × ×™×§×•×œ â€“ ×¢×•×–×¨×ª ×“×™×’×™×˜×œ×™×ª</h2>
  <form id="assistantForm">
    <input type="text" id="plateInput" name="plate" placeholder="××¡×¤×¨ ×¨×›×‘ (××•×¤×¦×™×•× ×œ×™)">
    
    <!-- Modern input container with integrated microphone -->
    <div class="input-container">
      <textarea id="freeQuery" name="query" class="input-with-mic" placeholder="××” ×ª×¨×¦×” ×œ×“×¢×ª ××• ×œ×‘×§×©? ××¤×©×¨ ×œ×›×ª×•×‘ ××• ×œ×”×§×™×© ×¢×œ ×”××™×§×¨×•×¤×•×Ÿ ×œ×“×‘×¨..."></textarea>
      <button type="button" id="micBtn" class="mic-button" title="×œ×—×¥ ×›×“×™ ×œ×”×§×œ×™×˜ ×§×•×œ">
        ğŸ¤
      </button>
    </div>
    
    <!-- Modern button container -->
    <div class="button-container">
      <button type="button" class="btn-modern btn-clear" onclick="clearForm()">
        ğŸ—‘ï¸ × ×§×”
      </button>
      <button type="submit" id="sendBtn" class="btn-modern btn-send">
        <span>ğŸ“¤</span>
        ×©×œ×— ×©××œ×”
      </button>
      <button type="button" class="btn-modern btn-secondary" onclick="window.location.href='selection.html'">
        â†©ï¸ ×—×–×•×¨ ×œ×‘×—×™×¨×”
      </button>
    </div>
  </form>
</div>
<div id="agentResponse" class="floating-response" style="display:none;"></div>
<script>
  window.addEventListener('DOMContentLoaded', () => {
    // Enhanced authentication audit
    const userAuthToken = sessionStorage.getItem('auth');
    const loginTime = sessionStorage.getItem('loginTime');
    const password = sessionStorage.getItem('password');
    const plate = sessionStorage.getItem('plate');
    
    console.group("ğŸ” Nicole Authentication Audit");
    console.log("ğŸ“Š Authentication State:", {
      auth_token: userAuthToken ? userAuthToken.substring(0, 20) + '...' : 'MISSING',
      auth_length: userAuthToken?.length || 0,
      login_time: loginTime,
      password_exists: !!password,
      password_type: password ? typeof password : 'undefined',
      plate_preloaded: plate || 'NONE',
      session_keys: Object.keys(sessionStorage).sort(),
      timestamp: new Date().toISOString()
    });
    
    // Check authentication validity
    const isValidAuth = userAuthToken && loginTime;
    console.log("ğŸ« Auth Validation:", {
      has_auth_token: !!userAuthToken,
      has_login_time: !!loginTime,
      is_valid: isValidAuth,
      login_age_minutes: loginTime ? Math.round((Date.now() - new Date(loginTime).getTime()) / 60000) : 'N/A'
    });
    
    // Check for auth conflicts or issues
    const authIssues = [];
    if (!userAuthToken) authIssues.push('Missing auth token');
    if (!loginTime) authIssues.push('Missing login time');
    if (!password && !userAuthToken) authIssues.push('No password fallback');
    
    if (authIssues.length > 0) {
      console.warn("âš ï¸ Authentication Issues:", authIssues);
    }
    
    if (!isValidAuth) {
      console.error("âŒ Authentication failed, redirecting to login");
      console.log("ğŸ”„ Redirect reason:", authIssues.join(', '));
      alert("×”×’×™×©×” ×—×¡×•××” - ×× × ×”×ª×—×‘×¨ ×“×¨×š ×“×£ ×”×‘×™×ª");
      window.location.href = 'index.html';
      return;
    }
    
    console.log("âœ… Authentication verified successfully");
    console.groupEnd();
    
    // Pre-populate plate if available
    if (plate) {
      document.getElementById('plateInput').value = plate;
      console.log("ğŸš— Pre-populated plate number:", plate);
    }
    
    // Store auth audit in session for debugging
    sessionStorage.setItem('nicole_auth_audit', JSON.stringify({
      timestamp: new Date().toISOString(),
      auth_valid: true,
      auth_method: password ? 'password' : 'auth_token',
      login_age_minutes: Math.round((Date.now() - new Date(loginTime).getTime()) / 60000)
    }));
    
    // Initialize modern UI functionality
    initializeModernUI();
  });

  // Helper function to detect browser info
  function getBrowserInfo() {
    const ua = navigator.userAgent;
    if (ua.includes('Chrome')) return 'Chrome';
    if (ua.includes('Firefox')) return 'Firefox';
    if (ua.includes('Safari') && !ua.includes('Chrome')) return 'Safari';
    if (ua.includes('Edge')) return 'Edge';
    if (ua.includes('Opera')) return 'Opera';
    return 'Unknown';
  }

  function clearForm() {
    document.getElementById('plateInput').value = '';
    document.getElementById('freeQuery').value = '';
    document.getElementById('freeQuery').focus();
  }

  function initializeModernUI() {
    const micBtn = document.getElementById('micBtn');
    const textarea = document.getElementById('freeQuery');
    const sendBtn = document.getElementById('sendBtn');
    
    // Enhanced microphone button functionality
    let isRecording = false;
    let recordingTimeout;
    let inactivityTimeout;
    let wasVoiceInput = false; // Track if last input was from voice
    const MAX_RECORDING_TIME = 60000; // 60 seconds max recording
    const INACTIVITY_TIMEOUT = 15000; // 15 seconds of silence
    
    micBtn.addEventListener('click', function() {
      if (micBtn.disabled) return;
      
      if (!isRecording) {
        startRecording();
      } else {
        stopRecording();
      }
    });
    
    // Initialize speech recognition
    let recognition;
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.lang = 'he-IL';
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;
      recognition.continuous = false;

      recognition.addEventListener('result', (event) => {
        const transcript = event.results[0][0].transcript;
        textarea.value = transcript;
        
        // Mark that this input came from voice
        wasVoiceInput = true;
        
        // Reset inactivity timeout when speech is detected
        if (inactivityTimeout) {
          clearTimeout(inactivityTimeout);
          inactivityTimeout = null;
        }
        
        stopRecording();
        console.log('ğŸ¤ Speech recognized:', transcript);
      });

      recognition.addEventListener('error', (event) => {
        const errorDetails = {
          error_type: event.error,
          timestamp: new Date().toISOString(),
          user_agent: navigator.userAgent,
          browser: getBrowserInfo(),
          mic_permissions: 'unknown'
        };
        
        console.group('ğŸš¨ Microphone Error Analysis');
        console.error('ğŸ¤ Speech recognition error:', event.error);
        console.log('ğŸ“Š Error Details:', errorDetails);
        
        stopRecording();
        
        let errorMessage = '×©×’×™××” ×‘×–×™×”×•×™ ×§×•×œ';
        let troubleshooting = '';
        let severity = 'medium';
        
        switch(event.error) {
          case 'no-speech':
            errorMessage = '×œ× ×–×•×”×” ×“×™×‘×•×¨. ×× × × ×¡×” ×©×•×‘ ×•×“×‘×¨ ×‘×§×•×œ ×‘×¨×•×¨.';
            troubleshooting = '×‘×“×•×§ ×©×”××™×§×¨×•×¤×•×Ÿ ×¢×•×‘×“ ×•×©××™×Ÿ ×¨×¢×© ×¡×‘×™×‘×”';
            severity = 'low';
            break;
          case 'audio-capture':
            errorMessage = '×œ× × ×™×ª×Ÿ ×œ×’×©×ª ×œ××™×§×¨×•×¤×•×Ÿ. ×× × ×‘×“×•×§ ××ª ×”×”×¨×©××•×ª ×•×”×—×™×‘×•×¨.';
            troubleshooting = '1. ×‘×“×•×§ ×©×”××™×§×¨×•×¤×•×Ÿ ××—×•×‘×¨\n2. ××©×¨ ×”×¨×©××•×ª ×œ××™×§×¨×•×¤×•×Ÿ\n3. ×¡×’×•×¨ ×™×™×©×•××™× ××—×¨×™× ×©×¢×©×•×™×™× ×œ×”×©×ª××© ×‘××™×§×¨×•×¤×•×Ÿ';
            severity = 'high';
            break;
          case 'not-allowed':
            errorMessage = '×’×™×©×” ×œ××™×§×¨×•×¤×•×Ÿ × ×“×—×ª×”. ×× × ××©×¨ ×”×¨×©××” ×‘×”×’×“×¨×•×ª ×”×“×¤×“×¤×Ÿ.';
            troubleshooting = '×œ×—×¥ ×¢×œ ×¡××œ ×”××™×§×¨×•×¤×•×Ÿ ×‘×©×•×¨×ª ×”×›×ª×•×‘×ª ×•××©×¨ ×”×¨×©××”';
            severity = 'high';
            break;
          case 'network':
            errorMessage = '×©×’×™××ª ×¨×©×ª. ×× × ×‘×“×•×§ ××ª ×”×—×™×‘×•×¨ ×œ××™× ×˜×¨× ×˜.';
            troubleshooting = '×‘×“×•×§ ×—×™×‘×•×¨ ×”××™× ×˜×¨× ×˜ ×•× ×¡×” ×©×•×‘';
            severity = 'medium';
            break;
          case 'aborted':
            errorMessage = '×–×™×”×•×™ ×”×§×•×œ ×”×•×¤×¡×§.';
            troubleshooting = '×–×•×”×™ ×©×’×™××” ×–×× ×™×ª, × ×™×ª×Ÿ ×œ× ×¡×•×ª ×©×•×‘';
            severity = 'low';
            break;
          case 'service-not-allowed':
            errorMessage = '×©×™×¨×•×ª ×–×™×”×•×™ ×§×•×œ ×œ× ×–××™×Ÿ.';
            troubleshooting = '×”×©×™×¨×•×ª ×¢×©×•×™ ×œ×”×™×•×ª ×—×¡×•× ××• ×œ× ×–××™×Ÿ ×‘××–×•×¨ ×©×œ×š';
            severity = 'high';
            break;
          default:
            errorMessage = `×©×’×™××” ×‘×–×™×”×•×™ ×§×•×œ: ${event.error}`;
            troubleshooting = '×©×’×™××” ×œ× ××–×•×”×”, × ×¡×” ×œ×¨×¢× ×Ÿ ××ª ×”×“×£';
            severity = 'medium';
        }
        
        // Log detailed error for debugging
        console.log('ğŸ› ï¸ Error Analysis:', {
          error_code: event.error,
          message: errorMessage,
          troubleshooting: troubleshooting,
          severity: severity,
          browser_support: !!window.webkitSpeechRecognition || !!window.SpeechRecognition,
          permissions_api: !!navigator.permissions
        });
        
        // Save error to session for pattern analysis
        const micErrors = JSON.parse(sessionStorage.getItem('nicole_mic_errors') || '[]');
        micErrors.push({
          ...errorDetails,
          message: errorMessage,
          severity: severity,
          troubleshooting: troubleshooting
        });
        // Keep only last 20 errors
        if (micErrors.length > 20) micErrors.shift();
        sessionStorage.setItem('nicole_mic_errors', JSON.stringify(micErrors));
        
        console.groupEnd();
        
        // Show user-friendly error with troubleshooting
        const fullMessage = `${errorMessage}\n\n×¤×ª×¨×•×Ÿ ××•×¦×¢:\n${troubleshooting}`;
        alert(fullMessage);
        
        // If it's a critical error, disable mic button temporarily
        if (severity === 'high') {
          micBtn.style.opacity = '0.5';
          micBtn.disabled = true;
          setTimeout(() => {
            micBtn.style.opacity = '1';
            micBtn.disabled = false;
          }, 10000); // Re-enable after 10 seconds
        }
      });

      recognition.addEventListener('end', () => {
        stopRecording();
      });
      
      // Cleanup function for page unload
      window.addEventListener('beforeunload', () => {
        if (isRecording) {
          stopRecording();
        }
        if (recordingTimeout) clearTimeout(recordingTimeout);
        if (inactivityTimeout) clearTimeout(inactivityTimeout);
      });
      
      // Cleanup function for visibility changes (tab switches)
      document.addEventListener('visibilitychange', () => {
        if (document.hidden && isRecording) {
          console.log('ğŸ¤ Tab hidden while recording, stopping...');
          stopRecording();
        }
      });
    } else {
      // Speech recognition not supported
      micBtn.style.opacity = '0.5';
      micBtn.style.cursor = 'not-allowed';
      micBtn.title = '×–×™×”×•×™ ×§×•×œ ×œ× × ×ª××š ×‘×“×¤×“×¤×Ÿ ×–×”';
      micBtn.disabled = true;
    }
    
    async function startRecording() {
      if (!recognition) {
        alert('×–×™×”×•×™ ×§×•×œ ×œ× × ×ª××š ×‘×“×¤×“×¤×Ÿ ×–×”');
        return;
      }

      // Check microphone permissions
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop()); // Stop the stream immediately
      } catch (error) {
        console.error('ğŸ¤ Microphone permission error:', error);
        if (error.name === 'NotAllowedError') {
          alert('× ×“×¨×©×ª ×”×¨×©××” ×œ××™×§×¨×•×¤×•×Ÿ ×›×“×™ ×œ×”×©×ª××© ×‘×–×™×”×•×™ ×§×•×œ. ×× × ××©×¨ ××ª ×”×”×¨×©××” ×•× ×¡×” ×©×•×‘.');
        } else if (error.name === 'NotFoundError') {
          alert('×œ× × ××¦× ××™×§×¨×•×¤×•×Ÿ. ×× × ×—×‘×¨ ××™×§×¨×•×¤×•×Ÿ ×•× ×¡×” ×©×•×‘.');
        } else {
          alert('×©×’×™××” ×‘×’×™×©×” ×œ××™×§×¨×•×¤×•×Ÿ: ' + error.message);
        }
        return;
      }

      isRecording = true;
      micBtn.classList.add('recording');
      micBtn.innerHTML = 'â¹ï¸';
      micBtn.title = '×œ×—×¥ ×›×“×™ ×œ×”×¤×¡×™×§ ×”×§×œ×˜×”';
      
      // Add visual feedback to textarea
      textarea.style.borderColor = '#ff6b6b';
      textarea.placeholder = 'ğŸ¤ ××§×œ×™×˜... ×“×‘×¨ ×¢×›×©×™×• ××• ×œ×—×¥ ×©×•×‘ ×›×“×™ ×œ×”×¤×¡×™×§';
      
      // Set maximum recording timeout
      recordingTimeout = setTimeout(() => {
        console.log('ğŸ¤ Maximum recording time reached, stopping...');
        stopRecording();
        alert('×”×§×œ×˜×” ×”×•×¤×¡×§×” ×œ××—×¨ ×“×§×”. ×× × × ×¡×” ×©×•×‘.');
      }, MAX_RECORDING_TIME);
      
      // Set inactivity timeout
      inactivityTimeout = setTimeout(() => {
        console.log('ğŸ¤ No speech detected for 15 seconds, stopping...');
        stopRecording();
        // Don't show alert for inactivity timeout - it's normal
      }, INACTIVITY_TIMEOUT);
      
      try {
        recognition.start();
        console.log('ğŸ¤ Speech recognition started with timeouts:', {
          max_time: MAX_RECORDING_TIME,
          inactivity_timeout: INACTIVITY_TIMEOUT
        });
      } catch (error) {
        console.error('ğŸ¤ Failed to start recognition:', error);
        if (error.message.includes('already started')) {
          // Recognition already running, stop and restart
          recognition.stop();
          setTimeout(() => {
            recognition.start();
          }, 100);
        } else {
          stopRecording();
          alert('×©×’×™××” ×‘×”×¤×¢×œ×ª ×–×™×”×•×™ ×§×•×œ: ' + error.message);
        }
      }
    }
    
    function stopRecording() {
      isRecording = false;
      micBtn.classList.remove('recording');
      micBtn.innerHTML = 'ğŸ¤';
      micBtn.title = '×œ×—×¥ ×›×“×™ ×œ×”×§×œ×™×˜ ×§×•×œ';
      
      // Clear all timeouts
      if (recordingTimeout) {
        clearTimeout(recordingTimeout);
        recordingTimeout = null;
      }
      if (inactivityTimeout) {
        clearTimeout(inactivityTimeout);
        inactivityTimeout = null;
      }
      
      // Reset textarea styling
      textarea.style.borderColor = '#e2e8f0';
      textarea.placeholder = '××” ×ª×¨×¦×” ×œ×“×¢×ª ××• ×œ×‘×§×©? ××¤×©×¨ ×œ×›×ª×•×‘ ××• ×œ×”×§×™×© ×¢×œ ×”××™×§×¨×•×¤×•×Ÿ ×œ×“×‘×¨...';
      
      if (recognition) {
        try {
          recognition.stop();
        } catch (error) {
          console.log('Recognition already stopped');
        }
      }
      
      console.log('ğŸ¤ Recording stopped with timeout cleanup...');
    }
    
    // Form submission handler
    const form = document.getElementById('assistantForm');
    form.addEventListener('submit', async function(e) {
      e.preventDefault();
      
      const query = textarea.value.trim();
      const plate = document.getElementById('plateInput').value.trim();
      
      // Check if this was voice input (will be reset after processing)
      const currentWasVoiceInput = wasVoiceInput;
      
      // Enhanced validation: require at least one field (plate OR query)
      if (!query && !plate) {
        alert('×× × ××œ× ×œ×¤×—×•×ª ×©×“×” ××—×“:\nâ€¢ ××¡×¤×¨ ×¨×›×‘, ××•\nâ€¢ ×©××œ×”/×‘×§×©×”');
        
        // Focus on the first empty field
        if (!plate) {
          document.getElementById('plateInput').focus();
          document.getElementById('plateInput').style.animation = 'shake 0.5s';
          setTimeout(() => { document.getElementById('plateInput').style.animation = ''; }, 500);
        } else {
          textarea.focus();
          textarea.style.animation = 'shake 0.5s';
          setTimeout(() => { textarea.style.animation = ''; }, 500);
        }
        
        console.log('âŒ Validation failed: Both fields empty', { plate, query });
        return;
      }
      
      // If only plate is provided, create a default query
      let finalQuery = query;
      if (!query && plate) {
        finalQuery = `××” ×”××™×“×¢ ×”×–××™×Ÿ ×¢×‘×•×¨ ×¨×›×‘ ××¡×¤×¨ ${plate}?`;
        console.log('ğŸ”„ Auto-generated query for plate-only request:', finalQuery);
      }
      
      console.log('âœ… Validation passed:', { 
        plate: plate || 'NONE', 
        query: finalQuery,
        validation_type: query && plate ? 'BOTH' : query ? 'QUERY_ONLY' : 'PLATE_ONLY'
      });
      
      // Add loading state
      sendBtn.innerHTML = '<span>â³</span> ×©×•×œ×—...';
      sendBtn.disabled = true;
      
      try {
        await submitQuery(plate, finalQuery, currentWasVoiceInput);
        
        // Reset voice input flag after successful submission
        wasVoiceInput = false;
      } catch (error) {
        console.error('Submit error:', error);
        alert('×©×’×™××” ×‘×©×œ×™×—×ª ×”×©××œ×”: ' + error.message);
      } finally {
        // Reset button state
        sendBtn.innerHTML = '<span>ğŸ“¤</span> ×©×œ×— ×©××œ×”';
        sendBtn.disabled = false;
      }
    });

    // Submit query to webhook and handle response
    async function submitQuery(plate, query, wasVoiceInput = false) {
      // Generate unique trace ID for this request
      const traceId = 'nicole_' + Date.now() + '_' + Math.random().toString(36).substring(2, 8);
      
      const payload = { 
        plate: plate, 
        free_query: query, 
        source: 'assistant-ui',
        password: sessionStorage.getItem('password') || sessionStorage.getItem('auth'),
        trace_id: traceId,
        timestamp: new Date().toISOString(),
        user_agent: navigator.userAgent,
        page_url: window.location.href
      };

      // Enhanced logging for debugging
      console.group(`ğŸ” Nicole Query Debug [${traceId}]`);
      console.log('ğŸ“¤ Outgoing Payload:', JSON.stringify(payload, null, 2));
      console.log('ğŸ”— Webhook URL:', WEBHOOKS?.SEARCH_MODULE || 'URL_NOT_LOADED');
      console.log('ğŸ”‘ Auth Data:', {
        password_exists: !!sessionStorage.getItem('password'),
        auth_exists: !!sessionStorage.getItem('auth'),
        auth_type: sessionStorage.getItem('password') ? 'password' : 'auth'
      });

      try {
        // Import webhook from webhook.js module
        const { WEBHOOKS } = await import('./webhook.js');
        const webhookUrl = WEBHOOKS.SEARCH_MODULE;
        
        console.log('ğŸŒ Sending request to:', webhookUrl);
        const startTime = performance.now();
        
        // Try using the webhook.js sendToWebhook function which handles CORS better
        let response;
        try {
          console.log('ğŸ“¡ Using sendToWebhook method for better CORS handling');
          const { sendToWebhook } = await import('./webhook.js');
          const webhookResponse = await sendToWebhook('SEARCH_MODULE', payload);
          
          if (webhookResponse) {
            // If sendToWebhook succeeds, process the response directly
            const responseText = webhookResponse?.text || webhookResponse?.answer || webhookResponse?.response || webhookResponse?.message || webhookResponse;
            
            if (responseText) {
              displayResponse(responseText);
              
              // Only auto-speak if user used microphone input (STT)
              if (wasVoiceInput) {
                console.log('ğŸ¤ Voice input detected, auto-playing TTS response');
                await speakResponse(responseText);
              } else {
                console.log('ğŸ“ Text input used, TTS available via manual button');
              }
              
              saveToHelper(query, responseText);
              return; // Exit successfully
            }
          }
        } catch (webhookError) {
          console.log('sendToWebhook failed, trying direct fetch:', webhookError);
        }
        
        // Fallback to direct fetch if sendToWebhook fails
        let lastError;
        const maxRetries = 2;
        
        for (let attempt = 1; attempt <= maxRetries; attempt++) {
          try {
            console.log(`ğŸ“¡ Direct fetch attempt ${attempt}/${maxRetries}`);
            response = await fetch(webhookUrl, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify(payload),
              timeout: 30000 // 30 second timeout
            });
            break; // Success, exit retry loop
          } catch (error) {
            lastError = error;
            console.warn(`âš ï¸ Attempt ${attempt} failed:`, error.message);
            
            if (attempt < maxRetries) {
              const retryDelay = attempt * 1000; // 1s, 2s delays
              console.log(`ğŸ”„ Retrying in ${retryDelay}ms...`);
              await new Promise(resolve => setTimeout(resolve, retryDelay));
            }
          }
        }
        
        if (!response) {
          throw new Error(`All ${maxRetries} attempts failed. Last error: ${lastError.message}`);
        }

        const endTime = performance.now();
        const responseTime = Math.round(endTime - startTime);
        
        console.log('ğŸ“¡ Response received:', {
          status: response.status,
          statusText: response.statusText,
          headers: Object.fromEntries(response.headers.entries()),
          responseTime: responseTime + 'ms'
        });

        // Read response as text first, then try to parse as JSON if possible
        const rawResponse = await response.text();
        let responseText;
        
        try {
          // Try to parse as JSON (like the working assistant.js)
          const data = JSON.parse(rawResponse);
          responseText = data?.text || data?.answer || data?.response || data?.message;
        } catch (e) {
          // If JSON parsing fails, use the raw text
          responseText = rawResponse;
        }
        
        if (responseText) {
          displayResponse(responseText);
          
          // Only auto-speak if user used microphone input (STT)
          if (wasVoiceInput) {
            console.log('ğŸ¤ Voice input detected, auto-playing TTS response');
            await speakResponse(responseText);
          } else {
            console.log('ğŸ“ Text input used, TTS available via manual button');
          }
          
          saveToHelper(query, responseText);
        }
      } catch (error) {
        console.error('ğŸš¨ Webhook error details:', {
          error_message: error.message,
          error_type: error.constructor.name,
          stack: error.stack,
          trace_id: traceId
        });
        
        // Check if this is a CORS error (Load failed)
        if (error.message.includes('Load failed') || error.name === 'TypeError') {
          console.log('ğŸŒ CORS error detected');
          
          // Show the explanation since we already tried alternative methods above
          displayResponse(`âŒ ×‘×¢×™×™×ª ×ª×§×©×•×¨×ª ×¢× × ×™×§×•×œ

ğŸ”§ × ×™×§×•×œ ×¤×•×¢×œ×ª ××‘×œ ×™×© ×‘×¢×™×” ×‘×§×‘×œ×ª ×”×ª×©×•×‘×•×ª.

ğŸ’¡ ×¤×ª×¨×•× ×•×ª ×–×× ×™×™×:
â€¢ × ×¡×” ×œ×¨×¢× ×Ÿ ××ª ×”×“×£ ×•×œ×©××•×œ ×©×•×‘
â€¢ ×‘×“×•×§ ×—×™×‘×•×¨ ×œ××™× ×˜×¨× ×˜
â€¢ ×¤× ×” ×œ×ª××™×›×” ×˜×›× ×™×ª ×× ×”×‘×¢×™×” × ××©×›×ª`);
          
          return;
        }
        
        displayResponse('×©×’×™××” ×‘×©×œ×™×—×ª ×”×‘×§×©×”. ×× × × ×¡×” ×©×•×‘ ×××•×—×¨ ×™×•×ª×¨.');
        throw error;
      } finally {
        console.groupEnd();
      }
    }

    // Display response in floating box with manual TTS controls
    function displayResponse(text) {
      const responseBox = document.getElementById('agentResponse');
      responseBox.style.display = 'block';
      responseBox.innerHTML = `
        <div style="margin-bottom: 10px; font-weight: bold; color: #667eea;">
          ğŸ‘©â€ğŸ’¼ ×ª×©×•×‘×ª × ×™×§×•×œ:
        </div>
        <div style="line-height: 1.5; margin-bottom: 10px;">
          ${text}
        </div>
        
        <!-- TTS Controls -->
        <div style="display: flex; gap: 8px; margin-bottom: 8px; align-items: center;">
          <button onclick="manualSpeakResponse('${text.replace(/'/g, "\\'")}', this)" style="
            background: #22c55e;
            color: white;
            border: none;
            border-radius: 6px;
            padding: 6px 12px;
            cursor: pointer;
            font-size: 12px;
            display: flex;
            align-items: center;
            gap: 4px;
          ">
            ğŸ”Š ×”×©××¢ ×ª×©×•×‘×”
          </button>
          
          <button onclick="testTTSDebug()" style="
            background: #f59e0b;
            color: white;
            border: none;
            border-radius: 6px;
            padding: 6px 12px;
            cursor: pointer;
            font-size: 12px;
          ">
            ğŸ”§ ×‘×“×•×§ TTS
          </button>
          
          
          <div id="ttsStatus" style="font-size: 11px; color: #666;"></div>
        </div>
        
        <button onclick="this.parentElement.style.display='none'" style="
          position: absolute; 
          top: 8px; 
          left: 8px; 
          background: #f0f0f0; 
          border: none; 
          border-radius: 50%; 
          width: 24px; 
          height: 24px; 
          cursor: pointer;
          font-size: 12px;
        ">âœ•</button>
      `;
    }
    
    // Manual TTS trigger for testing
    window.manualSpeakResponse = async function(text, buttonElement) {
      const statusDiv = document.getElementById('ttsStatus');
      const originalButtonText = buttonElement.innerHTML;
      
      try {
        buttonElement.innerHTML = 'â³ ××›×™×Ÿ ×§×•×œ...';
        buttonElement.disabled = true;
        
        if (statusDiv) statusDiv.textContent = '×‘×•×“×§ ×”×¨×©××•×ª ×“×¤×“×¤×Ÿ...';
        
        // Check if we have pending TTS audio from autoplay block
        if (window.pendingTTSAudio) {
          console.log('ğŸ”Š Playing pending TTS audio...');
          await window.pendingTTSAudio.play();
          window.pendingTTSAudio = null; // Clear after use
          if (statusDiv) statusDiv.textContent = 'âœ… ×”×•×©××¢ ××”×–×™×›×¨×•×Ÿ';
        } else {
          // Generate new TTS
          await speakResponse(text);
          if (statusDiv) statusDiv.textContent = 'âœ… ×”×•×©××¢ ×‘×”×¦×œ×—×”';
        }
        
      } catch (error) {
        console.error('Manual TTS Error:', error);
        if (statusDiv) statusDiv.textContent = `âŒ ×©×’×™××”: ${error.message}`;
      } finally {
        buttonElement.innerHTML = originalButtonText;
        buttonElement.disabled = false;
        
        // Clear status after 3 seconds
        setTimeout(() => {
          if (statusDiv) statusDiv.textContent = '';
        }, 3000);
      }
    };
    
    // TTS debugging function
    window.testTTSDebug = async function() {
      const statusDiv = document.getElementById('ttsStatus');
      
      console.group('ğŸ”§ TTS Debug Test');
      
      try {
        statusDiv.textContent = '×‘×•×“×§ TTS...';
        
        // Test 1: Check API availability
        console.log('ğŸ” Testing Google TTS API availability...');
        const testResponse = await fetch('https://texttospeech.googleapis.com/v1/voices?key=AIzaSyCYMIbBVJsGfOv1pbELD41-Lxe7OwsHd1o');
        
        console.log('ğŸ“¡ API Response Status:', testResponse.status);
        console.log('ğŸ“¡ API Response Headers:', Object.fromEntries(testResponse.headers.entries()));
        
        if (!testResponse.ok) {
          const errorText = await testResponse.text();
          console.error('âŒ API Error Details:', errorText);
          throw new Error(`API Error: ${testResponse.status} ${testResponse.statusText} - ${errorText}`);
        }
        
        const voicesData = await testResponse.json();
        console.log('âœ… Google TTS API is accessible, voices available:', voicesData.voices?.length || 0);
        
        // Test 2: Check browser audio support
        console.log('ğŸ” Testing browser audio support...');
        const testAudio = new Audio();
        const canPlayMp3 = testAudio.canPlayType('audio/mpeg');
        console.log('Audio MP3 support:', canPlayMp3);
        
        // Test 3: Try simple TTS
        console.log('ğŸ” Testing simple TTS...');
        await speakResponse('×‘×“×™×§×”');
        
        statusDiv.textContent = 'âœ… TTS ×¢×•×‘×“ ×ª×§×™×Ÿ';
        console.log('âœ… All TTS tests passed');
        
      } catch (error) {
        console.error('âŒ TTS Debug failed:', error);
        statusDiv.textContent = `âŒ ${error.message}`;
        
        // Additional debug info
        console.log('ğŸ” Debug Info:');
        console.log('- User Agent:', navigator.userAgent);
        console.log('- Browser supports Audio:', !!window.Audio);
        console.log('- HTTPS:', window.location.protocol === 'https:');
      } finally {
        console.groupEnd();
        
        // Clear status after 5 seconds
        setTimeout(() => {
          if (statusDiv) statusDiv.textContent = '';
        }, 5000);
      }
    };
    

    // Enhanced Text-to-Speech functionality using Google Cloud TTS
    async function speakResponse(text) {
      if (!text) {
        console.log('ğŸ”Š No text provided for TTS');
        return;
      }
      
      // Clean text for TTS - remove markdown, special characters, etc.
      let cleanText = text
        .replace(/\*\*/g, '') // Remove ** markdown
        .replace(/\*/g, '') // Remove * markdown
        .replace(/_{2,}/g, '') // Remove __ markdown
        .replace(/`{1,3}/g, '') // Remove code blocks
        .replace(/#{1,6}\s*/g, '') // Remove headings
        .replace(/\[([^\]]+)\]\([^)]+\)/g, '$1') // Replace links with text
        .replace(/\s+/g, ' ') // Normalize spaces
        .trim();
      
      // Limit text length for TTS (Google TTS has limits)
      const maxLength = 5000;
      const textForTTS = cleanText.length > maxLength ? cleanText.substring(0, maxLength) + '...' : cleanText;
      
      const apiKey = 'AIzaSyCYMIbBVJsGfOv1pbELD41-Lxe7OwsHd1o';
      const voice = 'he-IL-Wavenet-A'; // Female Hebrew voice
      
      console.log('ğŸ”Š Starting TTS for text length:', textForTTS.length);

      try {
        console.log('ğŸ”— Calling Google TTS API...');
        const response = await fetch(`https://texttospeech.googleapis.com/v1/text:synthesize?key=${apiKey}`, {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({
            input: { text: textForTTS },
            voice: { 
              languageCode: 'he-IL', 
              name: voice,
              ssmlGender: 'FEMALE'
            },
            audioConfig: { 
              audioEncoding: 'MP3',
              speakingRate: 1.0,
              pitch: 0.0,
              volumeGainDb: 0.0
            }
          })
        });

        console.log('ğŸ“¡ TTS API Response:', {
          status: response.status,
          statusText: response.statusText,
          headers: Object.fromEntries(response.headers.entries())
        });

        if (!response.ok) {
          const errorText = await response.text();
          console.error('âŒ TTS API Error Details:', errorText);
          
          // Try to parse error for more specific info
          try {
            const errorData = JSON.parse(errorText);
            console.error('âŒ Parsed API Error:', errorData);
            throw new Error(`TTS API error: ${response.status} - ${errorData.error?.message || errorText}`);
          } catch {
            throw new Error(`TTS API error: ${response.status} ${response.statusText} - ${errorText}`);
          }
        }

        const data = await response.json();
        
        if (data.audioContent) {
          const audio = new Audio('data:audio/mp3;base64,' + data.audioContent);
          
          // Add audio event listeners for better feedback
          audio.addEventListener('loadstart', () => {
            console.log('ğŸ”Š TTS audio loading...');
          });
          
          audio.addEventListener('canplay', () => {
            console.log('ğŸ”Š TTS audio ready to play');
          });
          
          audio.addEventListener('play', () => {
            console.log('ğŸ”Š Nicole is speaking...');
            // Add visual indicator that Nicole is speaking
            updateNicoleSpeakingStatus(true);
          });
          
          audio.addEventListener('ended', () => {
            console.log('ğŸ”Š Nicole finished speaking');
            updateNicoleSpeakingStatus(false);
          });
          
          audio.addEventListener('error', (e) => {
            console.error('ğŸ”Š Audio playback error:', e);
            updateNicoleSpeakingStatus(false);
          });
          
          // Handle browser autoplay restrictions
          try {
            // Try to play immediately
            await audio.play();
            console.log('âœ… TTS played successfully (auto)');
            
          } catch (autoplayError) {
            console.warn('ğŸ”‡ Browser blocked autoplay:', autoplayError.name);
            
            if (autoplayError.name === 'NotAllowedError') {
              // Browser blocked autoplay - show user notification
              console.log('ğŸ’¡ TTS requires user interaction due to browser autoplay policy');
              
              // Show visual notification that speech is ready but needs user click
              const responseBox = document.getElementById('agentResponse');
              if (responseBox) {
                const autoplayNotice = document.createElement('div');
                autoplayNotice.innerHTML = `
                  <div style="
                    background: rgba(249, 168, 37, 0.1);
                    border: 1px solid #f9a825;
                    color: #f57c00;
                    padding: 8px 12px;
                    border-radius: 8px;
                    margin-top: 8px;
                    font-size: 12px;
                    text-align: center;
                  ">
                    ğŸ”Š ×”×ª×©×•×‘×” ××•×›× ×” ×œ×”×©××¢×” - ×œ×—×¥ ×¢×œ ×›×¤×ª×•×¨ "×”×©××¢ ×ª×©×•×‘×”"
                  </div>
                `;
                responseBox.appendChild(autoplayNotice);
                
                // Store audio for manual playback
                window.pendingTTSAudio = audio;
              }
            } else {
              // Other playback error
              throw autoplayError;
            }
          }
          
        } else {
          console.warn('ğŸ”Š No audio content received from TTS API');
        }
      } catch (error) {
        console.error('ğŸ”Š Google TTS Error:', error);
        
        // Don't use automatic fallback - let user choose manually
        console.log('ğŸ’¡ TTS failed. User can use manual TTS buttons if needed.');
        
        // Provide detailed error feedback for debugging
        if (error.message.includes('network') || error.message.includes('fetch')) {
          console.log('ğŸ”Š TTS failed due to network issue');
        } else if (error.message.includes('quota') || error.message.includes('limit')) {
          console.log('ğŸ”Š TTS failed due to API quota limits');
        } else if (error.message.includes('403') || error.message.includes('401')) {
          console.log('ğŸ”Š TTS failed due to API authentication/authorization');
        }
        
        // Throw error so manual TTS can handle it appropriately
        throw error;
      }
    }
    
    
    // Helper function to show Nicole speaking status
    function updateNicoleSpeakingStatus(isSpeaking) {
      const responseBox = document.getElementById('agentResponse');
      if (responseBox && responseBox.style.display !== 'none') {
        const statusDiv = responseBox.querySelector('.nicole-speaking-status');
        
        if (isSpeaking) {
          if (!statusDiv) {
            const speakingIndicator = document.createElement('div');
            speakingIndicator.className = 'nicole-speaking-status';
            speakingIndicator.innerHTML = 'ğŸ”Š × ×™×§×•×œ ××“×‘×¨×ª...';
            speakingIndicator.style.cssText = `
              position: absolute;
              bottom: 8px;
              right: 8px;
              background: rgba(102, 126, 234, 0.1);
              color: #667eea;
              padding: 4px 8px;
              border-radius: 12px;
              font-size: 12px;
              font-weight: 500;
              animation: pulse 1.5s infinite;
            `;
            responseBox.appendChild(speakingIndicator);
          }
        } else {
          if (statusDiv) {
            statusDiv.remove();
          }
        }
      }
    }

    // Save conversation to helper for later reference
    function saveToHelper(question, answer) {
      try {
        const stored = sessionStorage.getItem("helper") || sessionStorage.getItem("expertise");
        if (!stored) return;

        const helper = JSON.parse(stored);
        if (!helper.assistant_history) helper.assistant_history = [];

        helper.assistant_history.push({
          question,
          answer,
          timestamp: new Date().toISOString()
        });

        sessionStorage.setItem("helper", JSON.stringify(helper));
        sessionStorage.setItem("expertise", JSON.stringify(helper));
        console.log('ğŸ’¾ Conversation saved to helper');
      } catch (error) {
        console.error('ğŸ’¾ Save to helper failed:', error);
      }
    }
    
    // Auto-resize textarea
    textarea.addEventListener('input', function() {
      this.style.height = 'auto';
      this.style.height = Math.min(this.scrollHeight, 200) + 'px';
    });
    
    // Enhanced focus states
    textarea.addEventListener('focus', function() {
      this.parentElement.style.transform = 'scale(1.02)';
    });
    
    textarea.addEventListener('blur', function() {
      this.parentElement.style.transform = 'scale(1)';
    });
    
    // Add global debug function for easy console access
    window.nicoleDebug = {
      getHistory: () => {
        const history = JSON.parse(sessionStorage.getItem('nicole_debug_history') || '[]');
        console.table(history);
        return history;
      },
      clearHistory: () => {
        sessionStorage.removeItem('nicole_debug_history');
        console.log('ğŸ§¹ Nicole debug history cleared');
      },
      getLastRequest: () => {
        const history = JSON.parse(sessionStorage.getItem('nicole_debug_history') || '[]');
        return history[history.length - 1] || null;
      },
      exportHistory: () => {
        const history = JSON.parse(sessionStorage.getItem('nicole_debug_history') || '[]');
        const blob = new Blob([JSON.stringify(history, null, 2)], {type: 'application/json'});
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `nicole_debug_${new Date().toISOString().split('T')[0]}.json`;
        a.click();
        console.log('ğŸ’¾ Debug history exported');
      },
      getMicErrors: () => {
        const errors = JSON.parse(sessionStorage.getItem('nicole_mic_errors') || '[]');
        console.table(errors);
        return errors;
      },
      clearMicErrors: () => {
        sessionStorage.removeItem('nicole_mic_errors');
        console.log('ğŸ§¹ Microphone error history cleared');
      },
      getErrorPatterns: () => {
        const errors = JSON.parse(sessionStorage.getItem('nicole_mic_errors') || '[]');
        const patterns = {};
        errors.forEach(error => {
          patterns[error.error_type] = (patterns[error.error_type] || 0) + 1;
        });
        console.log('ğŸ“Š Error Patterns:', patterns);
        return patterns;
      },
      testMicrophone: async () => {
        console.log('ğŸ¤ Testing microphone permissions...');
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          console.log('âœ… Microphone access granted');
          stream.getTracks().forEach(track => track.stop());
          return { success: true, message: 'Microphone working' };
        } catch (error) {
          console.error('âŒ Microphone test failed:', error);
          return { success: false, error: error.message };
        }
      }
    };
    
    console.log('ğŸ”§ Nicole Debug Tools Available:');
    console.log('  - nicoleDebug.getHistory() - View all request/response history');
    console.log('  - nicoleDebug.getLastRequest() - Get the most recent request');
    console.log('  - nicoleDebug.clearHistory() - Clear debug history');
    console.log('  - nicoleDebug.exportHistory() - Export history as JSON file');
    console.log('  - nicoleDebug.getMicErrors() - View microphone error history');
    console.log('  - nicoleDebug.getErrorPatterns() - Analyze error frequency');
    console.log('  - nicoleDebug.testMicrophone() - Test mic permissions');
    console.log('  - nicoleDebug.clearMicErrors() - Clear mic error history');
  }
</script>

<style>
  /* Add shake animation for validation feedback */
  @keyframes shake {
    0%, 100% { transform: translateX(0); }
    25% { transform: translateX(-5px); }
    75% { transform: translateX(5px); }
  }
  
  /* Enhance container animations */
  .input-container {
    transition: transform 0.2s ease;
  }
  
  /* Loading button state */
  .btn-send:disabled {
    opacity: 0.7;
    cursor: not-allowed;
    transform: none !important;
  }
</style>
</body>
</html>
